{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code from *Python Machine Learning 3rd Edition* by Sebastian Raschka, Packt Publishing Ltd. 2019\n",
    "\n",
    "Prepared for use in COSC-247 Machine Learning at Amherst College, Fall 2020, by Lee Spector (lspector@amherst.edu).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class labels: [0 1 2]\n"
     ]
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "\n",
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]]\n",
    "y = iris.target\n",
    "\n",
    "print('Class labels:', np.unique(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 3, 2, 1])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount([4, 4, 4, 5, 5, 6])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [50 50 50]\n",
      "Labels counts in y_train: [35 35 35]\n",
      "Labels counts in y_test: [15 15 15]\n"
     ]
    }
   ],
   "source": [
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [50 50 50]\n",
      "Labels counts in y_train: [36 32 37]\n",
      "Labels counts in y_test: [14 18 13]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=None)\n",
    "\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [50 50 50]\n",
      "Labels counts in y_train: [33 35 37]\n",
      "Labels counts in y_test: [17 15 13]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=2, stratify=None)\n",
    "\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function train_test_split in module sklearn.model_selection._split:\n",
      "\n",
      "train_test_split(*arrays, **options)\n",
      "    Split arrays or matrices into random train and test subsets\n",
      "    \n",
      "    Quick utility that wraps input validation and\n",
      "    ``next(ShuffleSplit().split(X, y))`` and application to input data\n",
      "    into a single call for splitting (and optionally subsampling) data in a\n",
      "    oneliner.\n",
      "    \n",
      "    Read more in the :ref:`User Guide <cross_validation>`.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    *arrays : sequence of indexables with same length / shape[0]\n",
      "        Allowed inputs are lists, numpy arrays, scipy-sparse\n",
      "        matrices or pandas dataframes.\n",
      "    \n",
      "    test_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the proportion\n",
      "        of the dataset to include in the test split. If int, represents the\n",
      "        absolute number of test samples. If None, the value is set to the\n",
      "        complement of the train size. If ``train_size`` is also None, it will\n",
      "        be set to 0.25.\n",
      "    \n",
      "    train_size : float or int, default=None\n",
      "        If float, should be between 0.0 and 1.0 and represent the\n",
      "        proportion of the dataset to include in the train split. If\n",
      "        int, represents the absolute number of train samples. If None,\n",
      "        the value is automatically set to the complement of the test size.\n",
      "    \n",
      "    random_state : int or RandomState instance, default=None\n",
      "        Controls the shuffling applied to the data before applying the split.\n",
      "        Pass an int for reproducible output across multiple function calls.\n",
      "        See :term:`Glossary <random_state>`.\n",
      "    \n",
      "    \n",
      "    shuffle : bool, default=True\n",
      "        Whether or not to shuffle the data before splitting. If shuffle=False\n",
      "        then stratify must be None.\n",
      "    \n",
      "    stratify : array-like, default=None\n",
      "        If not None, data is split in a stratified fashion, using this as\n",
      "        the class labels.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    splitting : list, length=2 * len(arrays)\n",
      "        List containing train-test split of inputs.\n",
      "    \n",
      "        .. versionadded:: 0.16\n",
      "            If the input is sparse, the output will be a\n",
      "            ``scipy.sparse.csr_matrix``. Else, output type is the same as the\n",
      "            input type.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> import numpy as np\n",
      "    >>> from sklearn.model_selection import train_test_split\n",
      "    >>> X, y = np.arange(10).reshape((5, 2)), range(5)\n",
      "    >>> X\n",
      "    array([[0, 1],\n",
      "           [2, 3],\n",
      "           [4, 5],\n",
      "           [6, 7],\n",
      "           [8, 9]])\n",
      "    >>> list(y)\n",
      "    [0, 1, 2, 3, 4]\n",
      "    \n",
      "    >>> X_train, X_test, y_train, y_test = train_test_split(\n",
      "    ...     X, y, test_size=0.33, random_state=42)\n",
      "    ...\n",
      "    >>> X_train\n",
      "    array([[4, 5],\n",
      "           [0, 1],\n",
      "           [6, 7]])\n",
      "    >>> y_train\n",
      "    [2, 0, 3]\n",
      "    >>> X_test\n",
      "    array([[2, 3],\n",
      "           [8, 9]])\n",
      "    >>> y_test\n",
      "    [1, 4]\n",
      "    \n",
      "    >>> train_test_split(y, shuffle=False)\n",
      "    [[0, 1, 2], [3, 4]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(train_test_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.4, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.7, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.1],\n",
       "       [1.5, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.1, 0.1],\n",
       "       [1.2, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.3, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.7, 0.3],\n",
       "       [1.5, 0.3],\n",
       "       [1.7, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1. , 0.2],\n",
       "       [1.7, 0.5],\n",
       "       [1.9, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.4],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.6, 0.2],\n",
       "       [1.5, 0.4],\n",
       "       [1.5, 0.1],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.2, 0.2],\n",
       "       [1.3, 0.2],\n",
       "       [1.4, 0.1],\n",
       "       [1.3, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.3],\n",
       "       [1.3, 0.2],\n",
       "       [1.6, 0.6],\n",
       "       [1.9, 0.4],\n",
       "       [1.4, 0.3],\n",
       "       [1.6, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [1.5, 0.2],\n",
       "       [1.4, 0.2],\n",
       "       [4.7, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.9, 1.5],\n",
       "       [4. , 1.3],\n",
       "       [4.6, 1.5],\n",
       "       [4.5, 1.3],\n",
       "       [4.7, 1.6],\n",
       "       [3.3, 1. ],\n",
       "       [4.6, 1.3],\n",
       "       [3.9, 1.4],\n",
       "       [3.5, 1. ],\n",
       "       [4.2, 1.5],\n",
       "       [4. , 1. ],\n",
       "       [4.7, 1.4],\n",
       "       [3.6, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.5, 1.5],\n",
       "       [4.1, 1. ],\n",
       "       [4.5, 1.5],\n",
       "       [3.9, 1.1],\n",
       "       [4.8, 1.8],\n",
       "       [4. , 1.3],\n",
       "       [4.9, 1.5],\n",
       "       [4.7, 1.2],\n",
       "       [4.3, 1.3],\n",
       "       [4.4, 1.4],\n",
       "       [4.8, 1.4],\n",
       "       [5. , 1.7],\n",
       "       [4.5, 1.5],\n",
       "       [3.5, 1. ],\n",
       "       [3.8, 1.1],\n",
       "       [3.7, 1. ],\n",
       "       [3.9, 1.2],\n",
       "       [5.1, 1.6],\n",
       "       [4.5, 1.5],\n",
       "       [4.5, 1.6],\n",
       "       [4.7, 1.5],\n",
       "       [4.4, 1.3],\n",
       "       [4.1, 1.3],\n",
       "       [4. , 1.3],\n",
       "       [4.4, 1.2],\n",
       "       [4.6, 1.4],\n",
       "       [4. , 1.2],\n",
       "       [3.3, 1. ],\n",
       "       [4.2, 1.3],\n",
       "       [4.2, 1.2],\n",
       "       [4.2, 1.3],\n",
       "       [4.3, 1.3],\n",
       "       [3. , 1.1],\n",
       "       [4.1, 1.3],\n",
       "       [6. , 2.5],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.1],\n",
       "       [5.6, 1.8],\n",
       "       [5.8, 2.2],\n",
       "       [6.6, 2.1],\n",
       "       [4.5, 1.7],\n",
       "       [6.3, 1.8],\n",
       "       [5.8, 1.8],\n",
       "       [6.1, 2.5],\n",
       "       [5.1, 2. ],\n",
       "       [5.3, 1.9],\n",
       "       [5.5, 2.1],\n",
       "       [5. , 2. ],\n",
       "       [5.1, 2.4],\n",
       "       [5.3, 2.3],\n",
       "       [5.5, 1.8],\n",
       "       [6.7, 2.2],\n",
       "       [6.9, 2.3],\n",
       "       [5. , 1.5],\n",
       "       [5.7, 2.3],\n",
       "       [4.9, 2. ],\n",
       "       [6.7, 2. ],\n",
       "       [4.9, 1.8],\n",
       "       [5.7, 2.1],\n",
       "       [6. , 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [4.9, 1.8],\n",
       "       [5.6, 2.1],\n",
       "       [5.8, 1.6],\n",
       "       [6.1, 1.9],\n",
       "       [6.4, 2. ],\n",
       "       [5.6, 2.2],\n",
       "       [5.1, 1.5],\n",
       "       [5.6, 1.4],\n",
       "       [6.1, 2.3],\n",
       "       [5.6, 2.4],\n",
       "       [5.5, 1.8],\n",
       "       [4.8, 1.8],\n",
       "       [5.4, 2.1],\n",
       "       [5.6, 2.4],\n",
       "       [5.1, 2.3],\n",
       "       [5.1, 1.9],\n",
       "       [5.9, 2.3],\n",
       "       [5.7, 2.5],\n",
       "       [5.2, 2.3],\n",
       "       [5. , 1.9],\n",
       "       [5.2, 2. ],\n",
       "       [5.4, 2.3],\n",
       "       [5.1, 1.8]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "sc.fit(X_train) ## Note that we standard only on the basis of the training set\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on class StandardScaler in module sklearn.preprocessing._data:\n",
      "\n",
      "class StandardScaler(sklearn.base.TransformerMixin, sklearn.base.BaseEstimator)\n",
      " |  StandardScaler(*, copy=True, with_mean=True, with_std=True)\n",
      " |  \n",
      " |  Standardize features by removing the mean and scaling to unit variance\n",
      " |  \n",
      " |  The standard score of a sample `x` is calculated as:\n",
      " |  \n",
      " |      z = (x - u) / s\n",
      " |  \n",
      " |  where `u` is the mean of the training samples or zero if `with_mean=False`,\n",
      " |  and `s` is the standard deviation of the training samples or one if\n",
      " |  `with_std=False`.\n",
      " |  \n",
      " |  Centering and scaling happen independently on each feature by computing\n",
      " |  the relevant statistics on the samples in the training set. Mean and\n",
      " |  standard deviation are then stored to be used on later data using\n",
      " |  :meth:`transform`.\n",
      " |  \n",
      " |  Standardization of a dataset is a common requirement for many\n",
      " |  machine learning estimators: they might behave badly if the\n",
      " |  individual features do not more or less look like standard normally\n",
      " |  distributed data (e.g. Gaussian with 0 mean and unit variance).\n",
      " |  \n",
      " |  For instance many elements used in the objective function of\n",
      " |  a learning algorithm (such as the RBF kernel of Support Vector\n",
      " |  Machines or the L1 and L2 regularizers of linear models) assume that\n",
      " |  all features are centered around 0 and have variance in the same\n",
      " |  order. If a feature has a variance that is orders of magnitude larger\n",
      " |  that others, it might dominate the objective function and make the\n",
      " |  estimator unable to learn from other features correctly as expected.\n",
      " |  \n",
      " |  This scaler can also be applied to sparse CSR or CSC matrices by passing\n",
      " |  `with_mean=False` to avoid breaking the sparsity structure of the data.\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <preprocessing_scaler>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  copy : boolean, optional, default True\n",
      " |      If False, try to avoid a copy and do inplace scaling instead.\n",
      " |      This is not guaranteed to always work inplace; e.g. if the data is\n",
      " |      not a NumPy array or scipy.sparse CSR matrix, a copy may still be\n",
      " |      returned.\n",
      " |  \n",
      " |  with_mean : boolean, True by default\n",
      " |      If True, center the data before scaling.\n",
      " |      This does not work (and will raise an exception) when attempted on\n",
      " |      sparse matrices, because centering them entails building a dense\n",
      " |      matrix which in common use cases is likely to be too large to fit in\n",
      " |      memory.\n",
      " |  \n",
      " |  with_std : boolean, True by default\n",
      " |      If True, scale the data to unit variance (or equivalently,\n",
      " |      unit standard deviation).\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  scale_ : ndarray or None, shape (n_features,)\n",
      " |      Per feature relative scaling of the data. This is calculated using\n",
      " |      `np.sqrt(var_)`. Equal to ``None`` when ``with_std=False``.\n",
      " |  \n",
      " |      .. versionadded:: 0.17\n",
      " |         *scale_*\n",
      " |  \n",
      " |  mean_ : ndarray or None, shape (n_features,)\n",
      " |      The mean value for each feature in the training set.\n",
      " |      Equal to ``None`` when ``with_mean=False``.\n",
      " |  \n",
      " |  var_ : ndarray or None, shape (n_features,)\n",
      " |      The variance for each feature in the training set. Used to compute\n",
      " |      `scale_`. Equal to ``None`` when ``with_std=False``.\n",
      " |  \n",
      " |  n_samples_seen_ : int or array, shape (n_features,)\n",
      " |      The number of samples processed by the estimator for each feature.\n",
      " |      If there are not missing samples, the ``n_samples_seen`` will be an\n",
      " |      integer, otherwise it will be an array.\n",
      " |      Will be reset on new calls to fit, but increments across\n",
      " |      ``partial_fit`` calls.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.preprocessing import StandardScaler\n",
      " |  >>> data = [[0, 0], [0, 0], [1, 1], [1, 1]]\n",
      " |  >>> scaler = StandardScaler()\n",
      " |  >>> print(scaler.fit(data))\n",
      " |  StandardScaler()\n",
      " |  >>> print(scaler.mean_)\n",
      " |  [0.5 0.5]\n",
      " |  >>> print(scaler.transform(data))\n",
      " |  [[-1. -1.]\n",
      " |   [-1. -1.]\n",
      " |   [ 1.  1.]\n",
      " |   [ 1.  1.]]\n",
      " |  >>> print(scaler.transform([[2, 2]]))\n",
      " |  [[3. 3.]]\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  scale: Equivalent function without the estimator API.\n",
      " |  \n",
      " |  :class:`sklearn.decomposition.PCA`\n",
      " |      Further removes the linear correlation across features with 'whiten=True'.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  NaNs are treated as missing values: disregarded in fit, and maintained in\n",
      " |  transform.\n",
      " |  \n",
      " |  We use a biased estimator for the standard deviation, equivalent to\n",
      " |  `numpy.std(x, ddof=0)`. Note that the choice of `ddof` is unlikely to\n",
      " |  affect model performance.\n",
      " |  \n",
      " |  For a comparison of the different scalers, transformers, and normalizers,\n",
      " |  see :ref:`examples/preprocessing/plot_all_scaling.py\n",
      " |  <sphx_glr_auto_examples_preprocessing_plot_all_scaling.py>`.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      StandardScaler\n",
      " |      sklearn.base.TransformerMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, copy=True, with_mean=True, with_std=True)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  fit(self, X, y=None)\n",
      " |      Compute the mean and std to be used for later scaling.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y\n",
      " |          Ignored\n",
      " |  \n",
      " |  inverse_transform(self, X, copy=None)\n",
      " |      Scale back the data to the original representation\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, optional (default: None)\n",
      " |          Copy the input X or not.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_tr : array-like, shape [n_samples, n_features]\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  partial_fit(self, X, y=None)\n",
      " |      Online computation of mean and std on X for later scaling.\n",
      " |      \n",
      " |      All of X is processed as a single batch. This is intended for cases\n",
      " |      when :meth:`fit` is not feasible due to very large number of\n",
      " |      `n_samples` or because X is read from a continuous stream.\n",
      " |      \n",
      " |      The algorithm for incremental mean and std is given in Equation 1.5a,b\n",
      " |      in Chan, Tony F., Gene H. Golub, and Randall J. LeVeque. \"Algorithms\n",
      " |      for computing the sample variance: Analysis and recommendations.\"\n",
      " |      The American Statistician 37.3 (1983): 242-247:\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape [n_samples, n_features]\n",
      " |          The data used to compute the mean and standard deviation\n",
      " |          used for later scaling along the features axis.\n",
      " |      \n",
      " |      y : None\n",
      " |          Ignored.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Transformer instance.\n",
      " |  \n",
      " |  transform(self, X, copy=None)\n",
      " |      Perform standardization by centering and scaling\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like, shape [n_samples, n_features]\n",
      " |          The data used to scale along the features axis.\n",
      " |      copy : bool, optional (default: None)\n",
      " |          Copy the input X or not.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  fit_transform(self, X, y=None, **fit_params)\n",
      " |      Fit to data, then transform it.\n",
      " |      \n",
      " |      Fits transformer to X and y with optional parameters fit_params\n",
      " |      and returns a transformed version of X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix, dataframe} of shape                 (n_samples, n_features)\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,), default=None\n",
      " |          Target values.\n",
      " |      \n",
      " |      **fit_params : dict\n",
      " |          Additional fit parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      X_new : ndarray array of shape (n_samples, n_features_new)\n",
      " |          Transformed array.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.TransformerMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      " |  \n",
      " |  set_params(self, **params)\n",
      " |      Set the parameters of this estimator.\n",
      " |      \n",
      " |      The method works on simple estimators as well as on nested objects\n",
      " |      (such as pipelines). The latter have parameters of the form\n",
      " |      ``<component>__<parameter>`` so that it's possible to update each\n",
      " |      component of a nested object.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **params : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(StandardScaler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(eta0=0.1, random_state=1)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import Perceptron\n",
    "\n",
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified examples: 1\n"
     ]
    }
   ],
   "source": [
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified examples: %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print('Accuracy: %.3f' % accuracy_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib.colors import ListedColormap\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def plot_decision_regions(X, y, classifier, test_idx=None, resolution=0.02):\n",
    "\n",
    "    # setup marker generator and color map\n",
    "    markers = ('s', 'x', 'o', '^', 'v')\n",
    "    colors = ('red', 'blue', 'lightgreen', 'gray', 'cyan')\n",
    "    cmap = ListedColormap(colors[:len(np.unique(y))])\n",
    "\n",
    "    # plot the decision surface\n",
    "    x1_min, x1_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    x2_min, x2_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx1, xx2 = np.meshgrid(np.arange(x1_min, x1_max, resolution),\n",
    "                           np.arange(x2_min, x2_max, resolution))\n",
    "    Z = classifier.predict(np.array([xx1.ravel(), xx2.ravel()]).T)\n",
    "    Z = Z.reshape(xx1.shape)\n",
    "    plt.contourf(xx1, xx2, Z, alpha=0.3, cmap=cmap)\n",
    "    plt.xlim(xx1.min(), xx1.max())\n",
    "    plt.ylim(xx2.min(), xx2.max())\n",
    "\n",
    "    for idx, cl in enumerate(np.unique(y)):\n",
    "        plt.scatter(x=X[y == cl, 0], \n",
    "                    y=X[y == cl, 1],\n",
    "                    alpha=0.8, \n",
    "                    c=colors[idx],\n",
    "                    marker=markers[idx], \n",
    "                    label=cl, \n",
    "                    edgecolor='black')\n",
    "\n",
    "    # highlight test examples\n",
    "    if test_idx:\n",
    "        # plot all examples\n",
    "        X_test, y_test = X[test_idx, :], y[test_idx]\n",
    "\n",
    "        plt.scatter(X_test[:, 0],\n",
    "                    X_test[:, 1],\n",
    "                    c=[], #c='', ## CHANGED TO AVOID A WARNING\n",
    "                    edgecolor='black',\n",
    "                    alpha=1.0,\n",
    "                    linewidth=1,\n",
    "                    marker='o',\n",
    "                    s=100, \n",
    "                    label='test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function vstack in module numpy:\n",
      "\n",
      "vstack(tup)\n",
      "    Stack arrays in sequence vertically (row wise).\n",
      "    \n",
      "    This is equivalent to concatenation along the first axis after 1-D arrays\n",
      "    of shape `(N,)` have been reshaped to `(1,N)`. Rebuilds arrays divided by\n",
      "    `vsplit`.\n",
      "    \n",
      "    This function makes most sense for arrays with up to 3 dimensions. For\n",
      "    instance, for pixel-data with a height (first axis), width (second axis),\n",
      "    and r/g/b channels (third axis). The functions `concatenate`, `stack` and\n",
      "    `block` provide more general stacking and concatenation operations.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of ndarrays\n",
      "        The arrays must have the same shape along all but the first axis.\n",
      "        1-D arrays must have the same length.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The array formed by stacking the given arrays, will be at least 2-D.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    hstack : Stack arrays in sequence horizontally (column wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third dimension).\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    vsplit : Split array into a list of multiple sub-arrays vertically.\n",
      "    block : Assemble arrays from blocks.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array([1, 2, 3])\n",
      "    >>> b = np.array([2, 3, 4])\n",
      "    >>> np.vstack((a,b))\n",
      "    array([[1, 2, 3],\n",
      "           [2, 3, 4]])\n",
      "    \n",
      "    >>> a = np.array([[1], [2], [3]])\n",
      "    >>> b = np.array([[2], [3], [4]])\n",
      "    >>> np.vstack((a,b))\n",
      "    array([[1],\n",
      "           [2],\n",
      "           [3],\n",
      "           [2],\n",
      "           [3],\n",
      "           [4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.vstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function hstack in module numpy:\n",
      "\n",
      "hstack(tup)\n",
      "    Stack arrays in sequence horizontally (column wise).\n",
      "    \n",
      "    This is equivalent to concatenation along the second axis, except for 1-D\n",
      "    arrays where it concatenates along the first axis. Rebuilds arrays divided\n",
      "    by `hsplit`.\n",
      "    \n",
      "    This function makes most sense for arrays with up to 3 dimensions. For\n",
      "    instance, for pixel-data with a height (first axis), width (second axis),\n",
      "    and r/g/b channels (third axis). The functions `concatenate`, `stack` and\n",
      "    `block` provide more general stacking and concatenation operations.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    tup : sequence of ndarrays\n",
      "        The arrays must have the same shape along all but the second axis,\n",
      "        except 1-D arrays which can be any length.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    stacked : ndarray\n",
      "        The array formed by stacking the given arrays.\n",
      "    \n",
      "    See Also\n",
      "    --------\n",
      "    stack : Join a sequence of arrays along a new axis.\n",
      "    vstack : Stack arrays in sequence vertically (row wise).\n",
      "    dstack : Stack arrays in sequence depth wise (along third axis).\n",
      "    concatenate : Join a sequence of arrays along an existing axis.\n",
      "    hsplit : Split array along second axis.\n",
      "    block : Assemble arrays from blocks.\n",
      "    \n",
      "    Examples\n",
      "    --------\n",
      "    >>> a = np.array((1,2,3))\n",
      "    >>> b = np.array((2,3,4))\n",
      "    >>> np.hstack((a,b))\n",
      "    array([1, 2, 3, 2, 3, 4])\n",
      "    >>> a = np.array([[1],[2],[3]])\n",
      "    >>> b = np.array([[2],[3],[4]])\n",
      "    >>> np.hstack((a,b))\n",
      "    array([[1, 2],\n",
      "           [2, 3],\n",
      "           [3, 4]])\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(np.hstack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_combined_std = np.vstack((X_train_std, X_test_std))\n",
    "y_combined = np.hstack((y_train, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.33269725, -1.30728421],\n",
       "       [-1.16537974, -1.30728421],\n",
       "       [ 0.84243039,  1.44587881],\n",
       "       [ 1.0655204 ,  1.18367281],\n",
       "       [-1.44424226, -1.30728421],\n",
       "       [ 1.0097479 ,  1.57698181],\n",
       "       [ 1.56747294,  1.18367281],\n",
       "       [-1.44424226, -1.30728421],\n",
       "       [ 1.12129291,  0.5281578 ],\n",
       "       [ 0.45202286,  0.1348488 ],\n",
       "       [-0.27301968, -0.2584602 ],\n",
       "       [ 0.06161534,  0.2659518 ],\n",
       "       [-1.38846976, -1.30728421],\n",
       "       [ 0.50779537,  0.0037458 ],\n",
       "       [ 0.11738784,  0.1348488 ],\n",
       "       [ 0.73088538,  0.92146681],\n",
       "       [-1.05383474, -1.30728421],\n",
       "       [-0.16147468, -0.2584602 ],\n",
       "       [ 0.06161534,  0.0037458 ],\n",
       "       [-1.22115225, -1.30728421],\n",
       "       [ 0.56356787,  0.79036381],\n",
       "       [ 1.73479045,  1.44587881],\n",
       "       [ 0.39625036,  0.3970548 ],\n",
       "       [ 0.39625036,  0.1348488 ],\n",
       "       [ 0.00584283, -0.1273572 ],\n",
       "       [ 1.0097479 ,  1.57698181],\n",
       "       [ 0.50779537,  0.2659518 ],\n",
       "       [ 1.0097479 ,  0.2659518 ],\n",
       "       [ 1.12129291,  1.31477581],\n",
       "       [ 0.73088538,  1.57698181],\n",
       "       [ 0.17316034,  0.1348488 ],\n",
       "       [-1.27692475, -1.04507821],\n",
       "       [ 1.62324544,  1.31477581],\n",
       "       [ 0.67511288,  0.92146681],\n",
       "       [ 0.56356787,  0.79036381],\n",
       "       [ 1.0097479 ,  1.18367281],\n",
       "       [ 0.22893285,  0.3970548 ],\n",
       "       [ 1.62324544,  1.05256981],\n",
       "       [ 0.9539754 ,  0.79036381],\n",
       "       [-1.22115225, -1.30728421],\n",
       "       [ 0.61934037,  0.79036381],\n",
       "       [-1.33269725, -1.30728421],\n",
       "       [ 0.73088538,  0.3970548 ],\n",
       "       [-1.05383474, -1.04507821],\n",
       "       [-1.55578727, -1.30728421],\n",
       "       [ 0.61934037,  0.3970548 ],\n",
       "       [-1.27692475, -1.30728421],\n",
       "       [-1.50001477, -1.43838721],\n",
       "       [ 0.9539754 ,  0.79036381],\n",
       "       [ 0.50779537,  0.3970548 ],\n",
       "       [-1.16537974, -1.17618121],\n",
       "       [-0.16147468, -0.2584602 ],\n",
       "       [ 0.17316034, -0.2584602 ],\n",
       "       [-1.27692475, -1.30728421],\n",
       "       [-1.27692475, -1.30728421],\n",
       "       [-1.27692475, -1.30728421],\n",
       "       [-0.04992967, -0.2584602 ],\n",
       "       [ 1.28861042,  1.70808482],\n",
       "       [-1.38846976, -1.17618121],\n",
       "       [ 0.61934037,  0.3970548 ],\n",
       "       [-1.38846976, -1.30728421],\n",
       "       [ 0.39625036,  0.5281578 ],\n",
       "       [ 1.23283791,  0.79036381],\n",
       "       [-1.22115225, -1.30728421],\n",
       "       [-1.33269725, -1.30728421],\n",
       "       [ 0.34047786,  0.0037458 ],\n",
       "       [ 0.73088538,  0.92146681],\n",
       "       [-0.10570217,  0.1348488 ],\n",
       "       [ 0.17316034,  0.1348488 ],\n",
       "       [ 0.56356787,  0.79036381],\n",
       "       [ 1.28861042,  1.44587881],\n",
       "       [ 0.39625036,  0.3970548 ],\n",
       "       [ 0.39625036,  0.3970548 ],\n",
       "       [ 0.89820289,  1.18367281],\n",
       "       [ 1.0097479 ,  1.31477581],\n",
       "       [ 0.45202286,  0.2659518 ],\n",
       "       [-1.27692475, -1.04507821],\n",
       "       [-1.16537974, -0.91397521],\n",
       "       [ 1.28861042,  0.92146681],\n",
       "       [ 0.73088538,  0.5281578 ],\n",
       "       [ 1.45592793,  1.05256981],\n",
       "       [ 0.67511288,  0.3970548 ],\n",
       "       [-1.27692475, -1.30728421],\n",
       "       [ 0.22893285,  0.1348488 ],\n",
       "       [ 0.73088538,  1.05256981],\n",
       "       [ 1.23283791,  1.70808482],\n",
       "       [-1.27692475, -1.17618121],\n",
       "       [-1.33269725, -1.30728421],\n",
       "       [ 1.0097479 ,  0.79036381],\n",
       "       [-1.33269725, -1.17618121],\n",
       "       [ 1.17706541,  1.44587881],\n",
       "       [ 0.06161534, -0.1273572 ],\n",
       "       [ 0.22893285,  0.0037458 ],\n",
       "       [ 0.28470535,  0.1348488 ],\n",
       "       [-1.27692475, -1.43838721],\n",
       "       [ 0.78665788,  1.44587881],\n",
       "       [ 0.34047786,  0.1348488 ],\n",
       "       [-1.38846976, -1.30728421],\n",
       "       [-1.33269725, -1.17618121],\n",
       "       [ 0.67511288,  0.65926081],\n",
       "       [-1.38846976, -1.17618121],\n",
       "       [ 0.11738784,  0.0037458 ],\n",
       "       [-1.22115225, -1.04507821],\n",
       "       [-1.27692475, -1.30728421],\n",
       "       [-1.38846976, -1.30728421],\n",
       "       [ 0.89820289,  1.44587881],\n",
       "       [-1.16537974, -1.04507821],\n",
       "       [-1.33269725, -1.17618121],\n",
       "       [ 0.39625036,  0.65926081],\n",
       "       [ 0.34047786,  0.2659518 ],\n",
       "       [ 0.11738784,  0.1348488 ],\n",
       "       [ 1.12129291,  0.79036381],\n",
       "       [ 0.39625036,  0.3970548 ],\n",
       "       [ 0.84243039,  0.92146681],\n",
       "       [-1.38846976, -1.04507821],\n",
       "       [-1.27692475, -1.04507821],\n",
       "       [ 0.61934037,  0.79036381],\n",
       "       [-1.33269725, -1.30728421],\n",
       "       [-0.27301968, -0.2584602 ],\n",
       "       [-1.33269725, -1.30728421],\n",
       "       [ 0.56356787,  0.2659518 ],\n",
       "       [ 0.73088538,  1.44587881],\n",
       "       [ 0.39625036,  0.3970548 ],\n",
       "       [ 0.28470535,  0.1348488 ],\n",
       "       [ 0.78665788,  1.05256981],\n",
       "       [ 1.17706541,  1.18367281],\n",
       "       [-1.33269725, -1.43838721],\n",
       "       [ 0.34047786,  0.2659518 ],\n",
       "       [ 0.61934037,  1.05256981],\n",
       "       [ 0.22893285,  0.1348488 ],\n",
       "       [ 0.50779537,  0.5281578 ],\n",
       "       [-0.4403372 , -0.1273572 ],\n",
       "       [ 1.0655204 ,  1.70808482],\n",
       "       [-1.22115225, -0.78287221],\n",
       "       [ 0.67511288,  1.05256981],\n",
       "       [-1.22115225, -1.30728421],\n",
       "       [-1.33269725, -1.30728421],\n",
       "       [ 0.11738784, -0.2584602 ],\n",
       "       [ 0.11738784,  0.1348488 ],\n",
       "       [ 1.40015543,  0.79036381],\n",
       "       [ 0.9539754 ,  1.18367281],\n",
       "       [-1.33269725, -1.43838721],\n",
       "       [-1.22115225, -1.30728421],\n",
       "       [-1.33269725, -1.30728421],\n",
       "       [ 0.50779537,  0.2659518 ],\n",
       "       [ 1.0655204 ,  1.44587881],\n",
       "       [ 0.73088538,  0.79036381],\n",
       "       [ 0.45202286,  0.3970548 ],\n",
       "       [-1.27692475, -1.30728421],\n",
       "       [-1.27692475, -1.43838721]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_combined_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 2, 0, 2, 2, 0, 2, 1, 1, 1, 0, 1, 1, 2, 0, 1, 1, 0, 2, 2,\n",
       "       1, 1, 1, 2, 1, 2, 2, 2, 1, 0, 2, 2, 2, 2, 1, 2, 2, 0, 2, 0, 2, 0,\n",
       "       0, 1, 0, 0, 2, 1, 0, 1, 1, 0, 0, 0, 1, 2, 0, 1, 0, 1, 2, 0, 0, 1,\n",
       "       2, 1, 1, 1, 2, 1, 1, 2, 2, 1, 0, 0, 2, 1, 2, 2, 0, 1, 2, 2, 0, 0,\n",
       "       2, 0, 2, 1, 1, 1, 0, 2, 1, 0, 0, 1, 0, 1, 0, 0, 0, 2, 0, 0, 2, 1,\n",
       "       1, 2, 1, 2, 0, 0, 2, 0, 1, 0, 1, 2, 1, 1, 2, 2, 0, 1, 2, 1, 1, 1,\n",
       "       2, 0, 2, 0, 0, 1, 1, 2, 2, 0, 0, 0, 1, 2, 2, 1, 0, 0])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_combined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "plt.rcdefaults() \n",
    "\n",
    "plot_decision_regions(X=X_combined_std, y=y_combined,\n",
    "                      classifier=ppn, test_idx=range(105, 150))\n",
    "plt.xlabel('petal length [standardized]')\n",
    "plt.ylabel('petal width [standardized]')\n",
    "plt.legend(loc='upper left')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Perceptron(eta0=0.1, random_state=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Perceptron in module sklearn.linear_model._perceptron object:\n",
      "\n",
      "class Perceptron(sklearn.linear_model._stochastic_gradient.BaseSGDClassifier)\n",
      " |  Perceptron(*, penalty=None, alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False)\n",
      " |  \n",
      " |  Perceptron\n",
      " |  \n",
      " |  Read more in the :ref:`User Guide <perceptron>`.\n",
      " |  \n",
      " |  Parameters\n",
      " |  ----------\n",
      " |  \n",
      " |  penalty : {'l2','l1','elasticnet'}, default=None\n",
      " |      The penalty (aka regularization term) to be used.\n",
      " |  \n",
      " |  alpha : float, default=0.0001\n",
      " |      Constant that multiplies the regularization term if regularization is\n",
      " |      used.\n",
      " |  \n",
      " |  fit_intercept : bool, default=True\n",
      " |      Whether the intercept should be estimated or not. If False, the\n",
      " |      data is assumed to be already centered.\n",
      " |  \n",
      " |  max_iter : int, default=1000\n",
      " |      The maximum number of passes over the training data (aka epochs).\n",
      " |      It only impacts the behavior in the ``fit`` method, and not the\n",
      " |      :meth:`partial_fit` method.\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  tol : float, default=1e-3\n",
      " |      The stopping criterion. If it is not None, the iterations will stop\n",
      " |      when (loss > previous_loss - tol).\n",
      " |  \n",
      " |      .. versionadded:: 0.19\n",
      " |  \n",
      " |  shuffle : bool, default=True\n",
      " |      Whether or not the training data should be shuffled after each epoch.\n",
      " |  \n",
      " |  verbose : int, default=0\n",
      " |      The verbosity level\n",
      " |  \n",
      " |  eta0 : double, default=1\n",
      " |      Constant by which the updates are multiplied.\n",
      " |  \n",
      " |  n_jobs : int, default=None\n",
      " |      The number of CPUs to use to do the OVA (One Versus All, for\n",
      " |      multi-class problems) computation.\n",
      " |      ``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.\n",
      " |      ``-1`` means using all processors. See :term:`Glossary <n_jobs>`\n",
      " |      for more details.\n",
      " |  \n",
      " |  random_state : int, RandomState instance, default=None\n",
      " |      Used to shuffle the training data, when ``shuffle`` is set to\n",
      " |      ``True``. Pass an int for reproducible output across multiple\n",
      " |      function calls.\n",
      " |      See :term:`Glossary <random_state>`.\n",
      " |  \n",
      " |  early_stopping : bool, default=False\n",
      " |      Whether to use early stopping to terminate training when validation.\n",
      " |      score is not improving. If set to True, it will automatically set aside\n",
      " |      a stratified fraction of training data as validation and terminate\n",
      " |      training when validation score is not improving by at least tol for\n",
      " |      n_iter_no_change consecutive epochs.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  validation_fraction : float, default=0.1\n",
      " |      The proportion of training data to set aside as validation set for\n",
      " |      early stopping. Must be between 0 and 1.\n",
      " |      Only used if early_stopping is True.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  n_iter_no_change : int, default=5\n",
      " |      Number of iterations with no improvement to wait before early stopping.\n",
      " |  \n",
      " |      .. versionadded:: 0.20\n",
      " |  \n",
      " |  class_weight : dict, {class_label: weight} or \"balanced\", default=None\n",
      " |      Preset for the class_weight fit parameter.\n",
      " |  \n",
      " |      Weights associated with classes. If not given, all classes\n",
      " |      are supposed to have weight one.\n",
      " |  \n",
      " |      The \"balanced\" mode uses the values of y to automatically adjust\n",
      " |      weights inversely proportional to class frequencies in the input data\n",
      " |      as ``n_samples / (n_classes * np.bincount(y))``\n",
      " |  \n",
      " |  warm_start : bool, default=False\n",
      " |      When set to True, reuse the solution of the previous call to fit as\n",
      " |      initialization, otherwise, just erase the previous solution. See\n",
      " |      :term:`the Glossary <warm_start>`.\n",
      " |  \n",
      " |  Attributes\n",
      " |  ----------\n",
      " |  coef_ : ndarray of shape = [1, n_features] if n_classes == 2 else         [n_classes, n_features]\n",
      " |      Weights assigned to the features.\n",
      " |  \n",
      " |  intercept_ : ndarray of shape = [1] if n_classes == 2 else [n_classes]\n",
      " |      Constants in decision function.\n",
      " |  \n",
      " |  n_iter_ : int\n",
      " |      The actual number of iterations to reach the stopping criterion.\n",
      " |      For multiclass fits, it is the maximum over every binary fit.\n",
      " |  \n",
      " |  classes_ : ndarray of shape (n_classes,)\n",
      " |      The unique classes labels.\n",
      " |  \n",
      " |  t_ : int\n",
      " |      Number of weight updates performed during training.\n",
      " |      Same as ``(n_iter_ * n_samples)``.\n",
      " |  \n",
      " |  Notes\n",
      " |  -----\n",
      " |  \n",
      " |  ``Perceptron`` is a classification algorithm which shares the same\n",
      " |  underlying implementation with ``SGDClassifier``. In fact,\n",
      " |  ``Perceptron()`` is equivalent to `SGDClassifier(loss=\"perceptron\",\n",
      " |  eta0=1, learning_rate=\"constant\", penalty=None)`.\n",
      " |  \n",
      " |  Examples\n",
      " |  --------\n",
      " |  >>> from sklearn.datasets import load_digits\n",
      " |  >>> from sklearn.linear_model import Perceptron\n",
      " |  >>> X, y = load_digits(return_X_y=True)\n",
      " |  >>> clf = Perceptron(tol=1e-3, random_state=0)\n",
      " |  >>> clf.fit(X, y)\n",
      " |  Perceptron()\n",
      " |  >>> clf.score(X, y)\n",
      " |  0.939...\n",
      " |  \n",
      " |  See also\n",
      " |  --------\n",
      " |  \n",
      " |  SGDClassifier\n",
      " |  \n",
      " |  References\n",
      " |  ----------\n",
      " |  \n",
      " |  https://en.wikipedia.org/wiki/Perceptron and references therein.\n",
      " |  \n",
      " |  Method resolution order:\n",
      " |      Perceptron\n",
      " |      sklearn.linear_model._stochastic_gradient.BaseSGDClassifier\n",
      " |      sklearn.linear_model._base.LinearClassifierMixin\n",
      " |      sklearn.base.ClassifierMixin\n",
      " |      sklearn.linear_model._stochastic_gradient.BaseSGD\n",
      " |      sklearn.linear_model._base.SparseCoefMixin\n",
      " |      sklearn.base.BaseEstimator\n",
      " |      builtins.object\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  __init__(self, *, penalty=None, alpha=0.0001, fit_intercept=True, max_iter=1000, tol=0.001, shuffle=True, verbose=0, eta0=1.0, n_jobs=None, random_state=0, early_stopping=False, validation_fraction=0.1, n_iter_no_change=5, class_weight=None, warm_start=False)\n",
      " |      Initialize self.  See help(type(self)) for accurate signature.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes defined here:\n",
      " |  \n",
      " |  __abstractmethods__ = frozenset()\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._stochastic_gradient.BaseSGDClassifier:\n",
      " |  \n",
      " |  fit(self, X, y, coef_init=None, intercept_init=None, sample_weight=None)\n",
      " |      Fit linear model with Stochastic Gradient Descent.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Training data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          Target values.\n",
      " |      \n",
      " |      coef_init : ndarray of shape (n_classes, n_features), default=None\n",
      " |          The initial coefficients to warm-start the optimization.\n",
      " |      \n",
      " |      intercept_init : ndarray of shape (n_classes,), default=None\n",
      " |          The initial intercept to warm-start the optimization.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), default=None\n",
      " |          Weights applied to individual samples.\n",
      " |          If not provided, uniform weights are assumed. These weights will\n",
      " |          be multiplied with class_weight (passed through the\n",
      " |          constructor) if class_weight is specified.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self :\n",
      " |          Returns an instance of self.\n",
      " |  \n",
      " |  partial_fit(self, X, y, classes=None, sample_weight=None)\n",
      " |      Perform one epoch of stochastic gradient descent on given samples.\n",
      " |      \n",
      " |      Internally, this method uses ``max_iter = 1``. Therefore, it is not\n",
      " |      guaranteed that a minimum of the cost function is reached after calling\n",
      " |      it once. Matters such as objective convergence and early stopping\n",
      " |      should be handled by the user.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : {array-like, sparse matrix}, shape (n_samples, n_features)\n",
      " |          Subset of the training data.\n",
      " |      \n",
      " |      y : ndarray of shape (n_samples,)\n",
      " |          Subset of the target values.\n",
      " |      \n",
      " |      classes : ndarray of shape (n_classes,), default=None\n",
      " |          Classes across all calls to partial_fit.\n",
      " |          Can be obtained by via `np.unique(y_all)`, where y_all is the\n",
      " |          target vector of the entire dataset.\n",
      " |          This argument is required for the first call to partial_fit\n",
      " |          and can be omitted in the subsequent calls.\n",
      " |          Note that y doesn't need to contain all labels in `classes`.\n",
      " |      \n",
      " |      sample_weight : array-like, shape (n_samples,), default=None\n",
      " |          Weights applied to individual samples.\n",
      " |          If not provided, uniform weights are assumed.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self :\n",
      " |          Returns an instance of self.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data and other attributes inherited from sklearn.linear_model._stochastic_gradient.BaseSGDClassifier:\n",
      " |  \n",
      " |  loss_functions = {'epsilon_insensitive': (<class 'sklearn.linear_model...\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.LinearClassifierMixin:\n",
      " |  \n",
      " |  decision_function(self, X)\n",
      " |      Predict confidence scores for samples.\n",
      " |      \n",
      " |      The confidence score for a sample is the signed distance of that\n",
      " |      sample to the hyperplane.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      array, shape=(n_samples,) if n_classes == 2 else (n_samples, n_classes)\n",
      " |          Confidence scores per (sample, class) combination. In the binary\n",
      " |          case, confidence score for self.classes_[1] where >0 means this\n",
      " |          class would be predicted.\n",
      " |  \n",
      " |  predict(self, X)\n",
      " |      Predict class labels for samples in X.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array_like or sparse matrix, shape (n_samples, n_features)\n",
      " |          Samples.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      C : array, shape [n_samples]\n",
      " |          Predicted class label per sample.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  score(self, X, y, sample_weight=None)\n",
      " |      Return the mean accuracy on the given test data and labels.\n",
      " |      \n",
      " |      In multi-label classification, this is the subset accuracy\n",
      " |      which is a harsh metric since you require for each sample that\n",
      " |      each label set be correctly predicted.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      X : array-like of shape (n_samples, n_features)\n",
      " |          Test samples.\n",
      " |      \n",
      " |      y : array-like of shape (n_samples,) or (n_samples, n_outputs)\n",
      " |          True labels for X.\n",
      " |      \n",
      " |      sample_weight : array-like of shape (n_samples,), default=None\n",
      " |          Sample weights.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      score : float\n",
      " |          Mean accuracy of self.predict(X) wrt. y.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Data descriptors inherited from sklearn.base.ClassifierMixin:\n",
      " |  \n",
      " |  __dict__\n",
      " |      dictionary for instance variables (if defined)\n",
      " |  \n",
      " |  __weakref__\n",
      " |      list of weak references to the object (if defined)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._stochastic_gradient.BaseSGD:\n",
      " |  \n",
      " |  set_params(self, **kwargs)\n",
      " |      Set and validate the parameters of estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      **kwargs : dict\n",
      " |          Estimator parameters.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self : object\n",
      " |          Estimator instance.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Readonly properties inherited from sklearn.linear_model._stochastic_gradient.BaseSGD:\n",
      " |  \n",
      " |  average_coef_\n",
      " |  \n",
      " |  average_intercept_\n",
      " |  \n",
      " |  standard_coef_\n",
      " |  \n",
      " |  standard_intercept_\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.linear_model._base.SparseCoefMixin:\n",
      " |  \n",
      " |  densify(self)\n",
      " |      Convert coefficient matrix to dense array format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member (back) to a numpy.ndarray. This is the\n",
      " |      default format of ``coef_`` and is required for fitting, so calling\n",
      " |      this method is only required on models that have previously been\n",
      " |      sparsified; otherwise, it is a no-op.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |  \n",
      " |  sparsify(self)\n",
      " |      Convert coefficient matrix to sparse format.\n",
      " |      \n",
      " |      Converts the ``coef_`` member to a scipy.sparse matrix, which for\n",
      " |      L1-regularized models can be much more memory- and storage-efficient\n",
      " |      than the usual numpy.ndarray representation.\n",
      " |      \n",
      " |      The ``intercept_`` member is not converted.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      self\n",
      " |          Fitted estimator.\n",
      " |      \n",
      " |      Notes\n",
      " |      -----\n",
      " |      For non-sparse models, i.e. when there are not many zeros in ``coef_``,\n",
      " |      this may actually *increase* memory usage, so use this method with\n",
      " |      care. A rule of thumb is that the number of zero elements, which can\n",
      " |      be computed with ``(coef_ == 0).sum()``, must be more than 50% for this\n",
      " |      to provide significant benefits.\n",
      " |      \n",
      " |      After calling this method, further fitting with the partial_fit\n",
      " |      method (if any) will not work until you call densify.\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Methods inherited from sklearn.base.BaseEstimator:\n",
      " |  \n",
      " |  __getstate__(self)\n",
      " |  \n",
      " |  __repr__(self, N_CHAR_MAX=700)\n",
      " |      Return repr(self).\n",
      " |  \n",
      " |  __setstate__(self, state)\n",
      " |  \n",
      " |  get_params(self, deep=True)\n",
      " |      Get parameters for this estimator.\n",
      " |      \n",
      " |      Parameters\n",
      " |      ----------\n",
      " |      deep : bool, default=True\n",
      " |          If True, will return the parameters for this estimator and\n",
      " |          contained subobjects that are estimators.\n",
      " |      \n",
      " |      Returns\n",
      " |      -------\n",
      " |      params : mapping of string to any\n",
      " |          Parameter names mapped to their values.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(ppn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['C',\n",
       " '__abstractmethods__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__setstate__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_abc_impl',\n",
       " '_allocate_parameter_mem',\n",
       " '_check_n_features',\n",
       " '_estimator_type',\n",
       " '_expanded_class_weight',\n",
       " '_fit',\n",
       " '_fit_binary',\n",
       " '_fit_multiclass',\n",
       " '_get_learning_rate_type',\n",
       " '_get_loss_function',\n",
       " '_get_param_names',\n",
       " '_get_penalty_type',\n",
       " '_get_tags',\n",
       " '_make_validation_score_cb',\n",
       " '_make_validation_split',\n",
       " '_more_tags',\n",
       " '_partial_fit',\n",
       " '_predict_proba_lr',\n",
       " '_repr_html_',\n",
       " '_repr_html_inner',\n",
       " '_repr_mimebundle_',\n",
       " '_validate_data',\n",
       " '_validate_params',\n",
       " 'alpha',\n",
       " 'average',\n",
       " 'average_coef_',\n",
       " 'average_intercept_',\n",
       " 'class_weight',\n",
       " 'classes_',\n",
       " 'coef_',\n",
       " 'decision_function',\n",
       " 'densify',\n",
       " 'early_stopping',\n",
       " 'epsilon',\n",
       " 'eta0',\n",
       " 'fit',\n",
       " 'fit_intercept',\n",
       " 'get_params',\n",
       " 'intercept_',\n",
       " 'l1_ratio',\n",
       " 'learning_rate',\n",
       " 'loss',\n",
       " 'loss_function_',\n",
       " 'loss_functions',\n",
       " 'max_iter',\n",
       " 'n_features_in_',\n",
       " 'n_iter_',\n",
       " 'n_iter_no_change',\n",
       " 'n_jobs',\n",
       " 'partial_fit',\n",
       " 'penalty',\n",
       " 'power_t',\n",
       " 'predict',\n",
       " 'random_state',\n",
       " 'score',\n",
       " 'set_params',\n",
       " 'shuffle',\n",
       " 'sparsify',\n",
       " 'standard_coef_',\n",
       " 'standard_intercept_',\n",
       " 't_',\n",
       " 'tol',\n",
       " 'validation_fraction',\n",
       " 'verbose',\n",
       " 'warm_start']"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(ppn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn.verbose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.16, NNZs: 2, Bias: -0.100000, T: 105, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.16, NNZs: 2, Bias: -0.100000, T: 210, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.16, NNZs: 2, Bias: -0.100000, T: 315, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.16, NNZs: 2, Bias: -0.100000, T: 420, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.16, NNZs: 2, Bias: -0.100000, T: 525, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.16, NNZs: 2, Bias: -0.100000, T: 630, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.18, NNZs: 2, Bias: -0.100000, T: 105, Avg. loss: 0.048942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.21, NNZs: 2, Bias: -0.100000, T: 210, Avg. loss: 0.058720\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.34, NNZs: 2, Bias: -0.000000, T: 315, Avg. loss: 0.046657\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.26, NNZs: 2, Bias: -0.100000, T: 420, Avg. loss: 0.061848\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.34, NNZs: 2, Bias: -0.100000, T: 525, Avg. loss: 0.058669\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.27, NNZs: 2, Bias: -0.100000, T: 630, Avg. loss: 0.043728\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.36, NNZs: 2, Bias: -0.000000, T: 735, Avg. loss: 0.050942\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 8\n",
      "Norm: 0.29, NNZs: 2, Bias: -0.100000, T: 840, Avg. loss: 0.054400\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 9\n",
      "Norm: 0.38, NNZs: 2, Bias: -0.100000, T: 945, Avg. loss: 0.051706\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 10\n",
      "Norm: 0.51, NNZs: 2, Bias: -0.000000, T: 1050, Avg. loss: 0.055821\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 11\n",
      "Norm: 0.49, NNZs: 2, Bias: -0.000000, T: 1155, Avg. loss: 0.059026\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 11 epochs took 0.00 seconds\n",
      "-- Epoch 1\n",
      "Norm: 0.25, NNZs: 2, Bias: -0.200000, T: 105, Avg. loss: 0.004733\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.40, NNZs: 2, Bias: -0.200000, T: 210, Avg. loss: 0.003316\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.41, NNZs: 2, Bias: -0.300000, T: 315, Avg. loss: 0.002422\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.43, NNZs: 2, Bias: -0.300000, T: 420, Avg. loss: 0.003032\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.42, NNZs: 2, Bias: -0.400000, T: 525, Avg. loss: 0.005206\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.46, NNZs: 2, Bias: -0.400000, T: 630, Avg. loss: 0.005538\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 7\n",
      "Norm: 0.47, NNZs: 2, Bias: -0.400000, T: 735, Avg. loss: 0.004637\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 7 epochs took 0.00 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   3 out of   3 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(eta0=0.1, random_state=1, verbose=1)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn = Perceptron(eta0=0.1, random_state=1, verbose=1)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X size reduced from 150 to 100\n",
      "y size reduced from 150 to 100\n"
     ]
    }
   ],
   "source": [
    "iris = datasets.load_iris()\n",
    "X = iris.data[:, [2, 3]].tolist()\n",
    "y = iris.target.tolist()\n",
    "X_reduced = [X[i] for i in range(len(X)) if y[i] in [0, 1]]\n",
    "print(\"X size reduced from\", len(X), \"to\", len(X_reduced))\n",
    "y_reduced = [v for v in y if v in [0, 1]]\n",
    "print(\"y size reduced from\", len(y), \"to\", len(y_reduced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels counts in y: [50 50]\n",
      "Labels counts in y_train: [35 35]\n",
      "Labels counts in y_test: [15 15]\n"
     ]
    }
   ],
   "source": [
    "X = np.array(X_reduced)\n",
    "y = np.array(y_reduced)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.3, random_state=1, stratify=y)\n",
    "\n",
    "print('Labels counts in y:', np.bincount(y))\n",
    "print('Labels counts in y_train:', np.bincount(y_train))\n",
    "print('Labels counts in y_test:', np.bincount(y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc = StandardScaler()\n",
    "sc.fit(X_train) ## Note that we standard only on the basis of the training set\n",
    "X_train_std = sc.transform(X_train)\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Misclassified examples: 0\n"
     ]
    }
   ],
   "source": [
    "ppn = Perceptron(eta0=0.1, random_state=1)\n",
    "ppn.fit(X_train_std, y_train)\n",
    "\n",
    "y_pred = ppn.predict(X_test_std)\n",
    "print('Misclassified examples: %d' % (y_test != y_pred).sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.20, NNZs: 2, Bias: 0.000000, T: 70, Avg. loss: 0.000077\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.20, NNZs: 2, Bias: 0.000000, T: 140, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 3\n",
      "Norm: 0.20, NNZs: 2, Bias: 0.000000, T: 210, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 4\n",
      "Norm: 0.20, NNZs: 2, Bias: 0.000000, T: 280, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 5\n",
      "Norm: 0.20, NNZs: 2, Bias: 0.000000, T: 350, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 6\n",
      "Norm: 0.20, NNZs: 2, Bias: 0.000000, T: 420, Avg. loss: 0.000000\n",
      "Total training time: 0.00 seconds.\n",
      "Convergence after 6 epochs took 0.00 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(eta0=0.1, random_state=1, verbose=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn = Perceptron(eta0=0.1, random_state=1, verbose=1)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- Epoch 1\n",
      "Norm: 0.20, NNZs: 2, Bias: 0.000000, T: 63, Avg. loss: 0.000077\n",
      "Total training time: 0.00 seconds.\n",
      "-- Epoch 2\n",
      "Norm: 0.20, NNZs: 2, Bias: 0.000000, T: 126, Avg. loss: 0.000000\n",
      "Total training time: 0.01 seconds.\n",
      "Convergence after 2 epochs took 0.01 seconds\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Perceptron(early_stopping=True, eta0=0.1, n_iter_no_change=1, random_state=1,\n",
       "           verbose=1)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ppn = Perceptron(eta0=0.1, random_state=1, verbose=1, early_stopping=True, n_iter_no_change=1)\n",
    "ppn.fit(X_train_std, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
